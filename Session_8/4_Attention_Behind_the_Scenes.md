# How Transformers Learn Attention: Behind the Scenes

---

## ğŸ” What Are Contextualized Vectors?

A **contextualized vector** is a word's numerical meaning that changes based on the words around it.

**Example:**
- â€œbankâ€ in â€œriver bankâ€ â†’ river side
- â€œbankâ€ in â€œmoney bankâ€ â†’ financial institution

ğŸ’¡ These meanings are different, so the vectors (numbers) for the word â€œbankâ€ are different in each case.

---

## ğŸ”„ How Transformers Create Contextual Vectors

Letâ€™s understand how this happens using **Self-Attention** and training.

---

### ğŸ§± Step 1: Initial Word Embeddings (Non-Contextual)

Each word is converted to a fixed vector (just a representation, not yet contextual).

**Example:**
- â€œTransformersâ€ â†’ `[0.2, 0.4, â€¦]`
- â€œareâ€ â†’ `[0.3, 0.1, â€¦]`
- â€œamazingâ€ â†’ `[0.5, 0.7, â€¦]`

---

### ğŸ”§ Step 2: Generate Query, Key, Value Vectors (Q, K, V)

Each embedding goes through three learned layers:

```
Q = x @ W_Q
K = x @ W_K
V = x @ W_V
```
Where:
- `x` = embedding of a word
- `@` = matrix multiplication
- `W_Q, W_K, W_V` = learned weights

These are used to calculate attention.

---

### ğŸ”¢ Step 3: Compute Attention Scores

For every pair of words:

```
Score = dot(Qáµ¢, Kâ±¼)
```
This tells us how much word *i* should attend to word *j*.

We apply **Softmax** on these scores to get attention weights.

**Example scores:**
- â€œamazingâ€ â†’ â€œTransformersâ€ = 8
- â€œamazingâ€ â†’ â€œareâ€ = 2
- â€œamazingâ€ â†’ â€œamazingâ€ = 5

After Softmax â†’ `[0.84, 0.01, 0.15]`

---

### ğŸ¯ Step 4: Weighted Sum of Value Vectors

Each wordâ€™s new vector =

> Sum of all value vectors (V), weighted by attention weights

This new vector is **contextualized** â€” it â€œknowsâ€ what to focus on.

---

### ğŸ” Happens in All Layers

Each layer builds deeper meaning:
- **Early layers:** grammar and structure
- **Later layers:** semantics and relationships

By the end, each word â€œunderstandsâ€ its full sentence context.

---

## â“How Does the Model Learn These Attention Weights?

Letâ€™s go step by step ğŸ‘‡

---

### ğŸ§ª Step 1: Training Data

We give the model:
- **Input:** â€œTransformers are amazingâ€
- **Output:** â€œà¤Ÿà¥à¤°à¤¾à¤‚à¤¸à¤«à¥‰à¤°à¥à¤®à¤° à¤…à¤¦à¥à¤­à¥à¤¤ à¤¹à¥ˆà¤‚â€

We donâ€™t tell the model:
- â€œamazingâ€ should attend to â€œTransformersâ€

---

### ğŸ§  Step 2: Model Makes a Guess

At first, the model might guess wrong:
- Predicted: â€œà¤¹à¥ˆà¤‚ à¤…à¤¦à¥à¤­à¥à¤¤ à¤Ÿà¥à¤°à¤¾à¤‚à¤¸à¤«à¥‰à¤°à¥à¤®à¤°â€

This is incorrect.

---

### ğŸ§® Step 3: Loss Function Calculates Error

The loss function checks how far the modelâ€™s prediction is from the actual answer.

- Wrong prediction = high loss
- Correct prediction = low loss

---

### ğŸ”§ Step 4: Backpropagation Fixes the Mistake

Using the loss, the model updates:

- `W_Q, W_K, W_V`
- Embedding layers
- Feedforward layers

Now, â€œamazingâ€ learns to pay more attention to â€œTransformersâ€, not â€œareâ€.

---

### ğŸ“ˆ Over Thousands of Sentencesâ€¦

The model sees:
- â€œBooks are interestingâ€
- â€œCars are fastâ€
- â€œTransformers are amazingâ€

It starts learning that adjectives like â€˜amazingâ€™ describe nouns, not verbs like â€œareâ€.

---

### ğŸ§  Analogy: How You Learned

You werenâ€™t told:
- â€œâ€˜Beautifulâ€™ describes a nounâ€

You learned by reading and correcting mistakes.

Transformers do the same â€” with:
- Vector math
- Prediction errors
- Millions of examples

---

## âœ… Recap: How Context Is Learned

| Component             | What It Does                                       |
|-----------------------|----------------------------------------------------|
| Input Embedding       | Basic word meaning (not contextual yet)            |
| Q, K, V Vectors       | Created from input via learned matrices            |
| Dot Product + Softmax | Creates attention weights (who to focus on)        |
| Value Vectors         | Combined using attention weights                   |
| Multi-Head Attention  | Looks at different relations in parallel           |
| Layers + Training     | Learn deeper meanings through repetition + feedback|

---

## Final Takeaway

- Transformers donâ€™t need to be told what to attend to.
- They learn it themselves â€” by making guesses, measuring errors, and adjusting focus over millions of examples.

**Thatâ€™s Self-Attention + Training in action. ğŸ”**
